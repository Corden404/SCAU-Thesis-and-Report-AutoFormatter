import os
import re
import sys
import subprocess
import time
import json
import urllib.request
import urllib.error

# å°è¯•å¯¼å…¥å‰ªåˆ‡æ¿åº“ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…åˆ™æç¤º
try:
    import pyperclip
except ImportError:
    print("[Error] ç¼ºå°‘ pyperclip åº“ã€‚è¯·è¿è¡Œ: pip install pyperclip")
    sys.exit(1)

# å°è¯•å¯¼å…¥ OpenAIï¼Œå¦‚æœåªç”¨ç½‘é¡µç‰ˆæ¨¡å¼å¯ä»¥ä¸éœ€è¦ï¼Œä½†ä¸ºäº†å…¼å®¹æ€§ä¿ç•™
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# ================= é…ç½®åŒºåŸŸ =================
# API é…ç½®ç°åœ¨é€šè¿‡ GUI ä¼ å…¥ï¼Œä¸å†ç¡¬ç¼–ç 

# è·¯å¾„é…ç½®ï¼ˆä»¥é¡¹ç›®æ ¹ç›®å½•ä¸ºåŸºå‡†ï¼‰
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
PROMPT_FILE = os.path.join(BASE_DIR, "prompt.txt")
MD_DIR = os.path.join(BASE_DIR, "md")
TEMP_DIR = os.path.join(BASE_DIR, "temp")

# ç¡®ä¿ç›®å½•å­˜åœ¨
if not os.path.exists(MD_DIR):
    os.makedirs(MD_DIR)
if not os.path.exists(TEMP_DIR):
    os.makedirs(TEMP_DIR)


class Preprocessor:
    def __init__(self, api_config=None):
        """
        Args:
            api_config: dict, åŒ…å« 'api_key', 'base_url', 'model_name', 'provider' ç­‰é…ç½®
        """
        self.client = None
        self.api_config = api_config or {}

    def init_api(self):
        """ä»…åœ¨éœ€è¦ API æ—¶åˆå§‹åŒ–"""
        if OpenAI is None:
            print("[Error] æœªå®‰è£… openai åº“ã€‚è¯·è¿è¡Œ: pip install openai")
            sys.exit(1)

        api_key = self.api_config.get("api_key", "")
        base_url = self.api_config.get("base_url", "")

        if not api_key:
            raise ValueError("API Key æœªé…ç½®")
        if not base_url:
            raise ValueError("Base URL æœªé…ç½®")

        self.client = OpenAI(api_key=api_key, base_url=base_url)

    def _build_chat_url(self, base_url):
        base = (base_url or "").rstrip("/")
        if base.endswith("/v1"):
            return f"{base}/chat/completions"
        return f"{base}/v1/chat/completions"

    def _call_ai_api_simple(self, raw_text):
        """å…¼å®¹æ¨¡å¼ï¼šç»•è¿‡ OpenAI SDKï¼Œç›´æ¥ HTTP è°ƒç”¨"""
        api_key = self.api_config.get("api_key", "")
        base_url = self.api_config.get("base_url", "")
        if not api_key:
            raise ValueError("API Key æœªé…ç½®")
        if not base_url:
            raise ValueError("Base URL æœªé…ç½®")

        system_prompt = self.get_system_prompt()
        model_name = self.api_config.get("model_name", "gpt-3.5-turbo")

        url = self._build_chat_url(base_url)
        payload = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ä»¥ä¸‹æ˜¯è®ºæ–‡åŸå§‹å†…å®¹ï¼Œè¯·æŒ‰è¦æ±‚å¤„ç†ï¼š\n\n{raw_text}"},
            ],
            "temperature": 0.05,
            "stream": False,
        }

        data = json.dumps(payload).encode("utf-8")
        req = urllib.request.Request(
            url,
            data=data,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}",
            },
            method="POST",
        )

        try:
            with urllib.request.urlopen(req, timeout=60) as resp:
                resp_text = resp.read().decode("utf-8", errors="ignore")
                result = json.loads(resp_text)
                return result["choices"][0]["message"]["content"]
        except urllib.error.HTTPError as e:
            detail = e.read().decode("utf-8", errors="ignore")
            raise RuntimeError(f"HTTP {e.code}: {detail}")
        except Exception as e:
            raise RuntimeError(str(e))

    def convert_to_plain_text(self, input_path):
        """æ­¥éª¤ 1: ä½¿ç”¨ Pandoc å°† docx/md/pdf è½¬æ¢ä¸ºçº¯æ–‡æœ¬"""
        print(f"[1/4] æ­£åœ¨è¯»å–å¹¶æ¸…æ´—åŸæ–‡ä»¶: {os.path.basename(input_path)}...")

        filename = os.path.basename(input_path)
        temp_txt_path = os.path.join(TEMP_DIR, f"{filename}.txt")

        # æ„å»º pandoc å‘½ä»¤ï¼šå¼ºåˆ¶è½¬æ¢ä¸º plain text
        cmd = f'pandoc "{input_path}" -t plain --wrap=none -o "{temp_txt_path}"'

        try:
            subprocess.run(cmd, shell=True, check=True)
            with open(temp_txt_path, "r", encoding="utf-8") as f:
                return f.read()
        except subprocess.CalledProcessError:
            print("[Error] Pandoc è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å®‰è£… Pandocã€‚")
            sys.exit(1)
        except Exception as e:
            print(f"[Error] è¯»å–æ–‡æœ¬å¤±è´¥: {e}")
            sys.exit(1)

    def get_system_prompt(self):
        """è¯»å–æœ¬åœ°çš„ prompt.txt"""
        if not os.path.exists(PROMPT_FILE):
            print(f"[Error] æ‰¾ä¸åˆ°æç¤ºè¯æ–‡ä»¶: {PROMPT_FILE}")
            sys.exit(1)
        with open(PROMPT_FILE, "r", encoding="utf-8") as f:
            return f.read()

    def call_ai_api(self, raw_text):
        """API æ¨¡å¼: ç›´æ¥è°ƒç”¨æ¥å£"""
        print("[2/4] [APIæ¨¡å¼] æ­£åœ¨å‘é€ç»™ AI è¿›è¡Œæ’ç‰ˆ (è¯·è€å¿ƒç­‰å¾…)...")
        try:
            self.init_api()
        except Exception as e:
            if "proxies" in str(e):
                return self._call_ai_api_simple(raw_text)
            raise

        system_prompt = self.get_system_prompt()
        model_name = self.api_config.get("model_name", "gpt-3.5-turbo")

        try:
            response = self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ä»¥ä¸‹æ˜¯è®ºæ–‡åŸå§‹å†…å®¹ï¼Œè¯·æŒ‰è¦æ±‚å¤„ç†ï¼š\n\n{raw_text}"},
                ],
                temperature=0.05,
                stream=False,
            )
            return response.choices[0].message.content
        except Exception as e:
            if "proxies" in str(e):
                return self._call_ai_api_simple(raw_text)
            print(f"[Error] AI API è°ƒç”¨å¤±è´¥: {e}")
            raise

    def prepare_web_mode(self, raw_text):
        """ç½‘é¡µæ¨¡å¼: æ‹¼æ¥ Prompt å¹¶å¤åˆ¶åˆ°å‰ªåˆ‡æ¿"""
        print("[2/4] [ç½‘é¡µæ¨¡å¼] æ­£åœ¨ç”Ÿæˆæç¤ºè¯...")

        base_prompt = self.get_system_prompt()
        placeholder = "[åœ¨æ­¤å¤„ç²˜è´´ä½ çš„è®ºæ–‡å†…å®¹]"

        # æ‹¼æ¥å®Œæ•´å†…å®¹
        if placeholder in base_prompt:
            full_content = base_prompt.replace(placeholder, raw_text)
        else:
            # å¦‚æœ prompt.txt é‡Œæ²¡æ‰¾åˆ°å ä½ç¬¦ï¼Œç›´æ¥æ‹¼åœ¨åé¢
            full_content = base_prompt + "\n\n" + raw_text

        # å¤åˆ¶åˆ°å‰ªåˆ‡æ¿
        try:
            pyperclip.copy(full_content)
            print("\n" + "=" * 50)
            print("âœ… å·²å°† [æç¤ºè¯ + è®ºæ–‡å†…å®¹] å¤åˆ¶åˆ°æ‚¨çš„å‰ªåˆ‡æ¿ï¼")
            print("=" * 50)
            print("è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š")
            print("1. æ‰“å¼€ AI ç½‘é¡µç«¯ (æ¨è DeepSeek R1 / ChatGPT o1)")
            print("2. ğŸ’¡ å¼ºçƒˆå»ºè®®å¼€å¯ã€æ·±åº¦æ€è€ƒ (R1)ã€‘æ¨¡å¼ï¼Œæ’ç‰ˆæ•ˆæœæ›´å¥½")
            print("3. åœ¨è¾“å…¥æ¡†æŒ‰ Ctrl+V ç²˜è´´å¹¶å‘é€")
            print("4. ç­‰å¾… AI ç”Ÿæˆå®Œæ¯•åï¼Œç‚¹å‡»ã€å¤åˆ¶ã€‘æŒ‰é’®å¤åˆ¶ AI çš„å›å¤")
            print("=" * 50)

            input("\nğŸ‘‰ å½“æ‚¨å·²å¤åˆ¶ AI çš„å›å¤åï¼Œè¯·åœ¨æ­¤æŒ‰å›è½¦é”®ç»§ç»­...")

            # ä»å‰ªåˆ‡æ¿è¯»å– AI çš„å›å¤
            print("æ­£åœ¨ä»å‰ªåˆ‡æ¿è¯»å–å†…å®¹...")
            ai_response = pyperclip.paste()

            if not ai_response or len(ai_response) < 10:
                print("[Warning] å‰ªåˆ‡æ¿å†…å®¹ä¼¼ä¹ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œè¯·ç¡®è®¤æ‚¨å·²å¤åˆ¶ AI çš„å›å¤ã€‚")
                retry = input("æ˜¯å¦é‡è¯•è¯»å–å‰ªåˆ‡æ¿? (y/n): ")
                if retry.lower() == "y":
                    ai_response = pyperclip.paste()
                else:
                    return None

            return ai_response

        except Exception as e:
            print(f"[Error] å‰ªåˆ‡æ¿æ“ä½œå¤±è´¥: {e}")
            return None

    def split_and_save(self, ai_response, output_dir=None):
        """æ­¥éª¤ 3: è§£æ AI è¿”å›çš„æ–‡æœ¬å¹¶æ‹†åˆ†æ–‡ä»¶

        Args:
            ai_response: AI è¿”å›çš„æ–‡æœ¬
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤çš„ MD_DIR
        """
        if not ai_response:
            return False

        print("[3/4] æ­£åœ¨æ‹†åˆ†å¹¶ä¿å­˜ Markdown æ–‡ä»¶...")

        # ç¡®å®šè¾“å‡ºç›®å½•
        target_dir = output_dir if output_dir else MD_DIR
        if not os.path.exists(target_dir):
            os.makedirs(target_dir)

        # ==================== ä¿®å¤æŠ¥é”™çš„å…³é”®éƒ¨åˆ† ====================
        # åŸæŠ¥é”™åŸå› ï¼šæ­£åˆ™è¡¨è¾¾å¼å­—ç¬¦ä¸²å¿…é¡»ç”¨å¼•å·åŒ…è£¹ï¼Œå¦åˆ™ Python ä¼šæŠŠ ``` å½“ä½œè¯­æ³•é”™è¯¯
        # ä¿®å¤åï¼šä½¿ç”¨ r'^...$' æ ¼å¼

        # 1. æ¸…æ´—ï¼šå»æ‰å¯èƒ½å­˜åœ¨çš„ markdown ä»£ç å—åŒ…è£¹
        # å»æ‰å¼€å¤´çš„ ```markdown æˆ– ```
        clean_response = re.sub(r"^```(markdown)?\s*", "", ai_response.strip())
        # å»æ‰ç»“å°¾çš„ ```
        clean_response = re.sub(r"\s*```$", "", clean_response)
        # ==========================================================

        # 2. æ­£åˆ™åŒ¹é…æ‹†åˆ†
        pattern = r"===FILE:\s*(.*?)===\s*(.*?)(?=(===FILE:|$))"
        matches = re.findall(pattern, clean_response, re.DOTALL)

        if not matches:
            print("[Error] æ— æ³•è§£æ AI è¿”å›çš„å†…å®¹ã€‚")
            print("è¯·æ£€æŸ¥ AI æ˜¯å¦ä¸¥æ ¼æŒ‰ç…§ '===FILE: filename===' æ ¼å¼è¾“å‡ºã€‚")
            # è°ƒè¯•ç”¨ï¼šå°†å†…å®¹ä¿å­˜åˆ° debug.txt æ–¹ä¾¿ç”¨æˆ·æŸ¥çœ‹
            debug_path = os.path.join(TEMP_DIR, "debug_ai_response.txt")
            with open(debug_path, "w", encoding="utf-8") as f:
                f.write(ai_response)
            print(f"å·²å°†åŸå§‹å†…å®¹ä¿å­˜è‡³: {debug_path}")
            return False

        saved_files = []
        for filename, content, _ in matches:
            filename = filename.strip()
            content = content.strip()

            save_path = os.path.join(target_dir, filename)

            with open(save_path, "w", encoding="utf-8") as f:
                f.write(content)
            saved_files.append(filename)
            print(f"   -> å·²ä¿å­˜: {filename}")

        return len(saved_files) > 0

    def run_build_engine(self):
        """æ­¥éª¤ 4: è°ƒç”¨æ„å»ºè„šæœ¬"""
        print("[4/4] å¯åŠ¨æ„å»ºå¼•æ“ (build_engine.py)...")
        build_script = os.path.join(BASE_DIR, "build_engine.py")

        if os.path.exists(build_script):
            subprocess.run(["python", build_script])
        else:
            print(f"[Error] æ‰¾ä¸åˆ°æ„å»ºè„šæœ¬: {build_script}")


def main():
    print("=" * 50)
    print("      SCAU è®ºæ–‡ AI é¢„å¤„ç†åŠ©æ‰‹")
    print("=" * 50)

    # 1. è·å–è¾“å…¥æ–‡ä»¶
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    else:
        input_file = input("è¯·è¾“å…¥åŸå§‹è®ºæ–‡æ–‡ä»¶è·¯å¾„ (docx/txt/md): ").strip().strip('"')

    if not os.path.exists(input_file):
        print("[Error] æ–‡ä»¶ä¸å­˜åœ¨")
        return

    processor = Preprocessor()

    # 2. é€‰æ‹©æ¨¡å¼
    print("\nè¯·é€‰æ‹©å¤„ç†æ¨¡å¼:")
    print("1. API è‡ªåŠ¨æ¨¡å¼ (éœ€é…ç½® Keyï¼Œå…¨è‡ªåŠ¨)")
    print("2. ç½‘é¡µç«¯æ‰‹åŠ¨æ¨¡å¼ (æ¨è DeepSeek R1ï¼Œæ•ˆæœå¥½ï¼Œå…è´¹)")
    mode = input("è¯·è¾“å…¥é€‰é¡¹ [2]: ").strip()

    # 3. æå–çº¯æ–‡æœ¬
    raw_text = processor.convert_to_plain_text(input_file)

    formatted_md = None
    if mode == "1":
        formatted_md = processor.call_ai_api(raw_text)
    else:
        # é»˜è®¤ä¸ºç½‘é¡µæ¨¡å¼
        formatted_md = processor.prepare_web_mode(raw_text)

    # 4. æ‹†åˆ†ä¸æ„å»º
    if formatted_md and processor.split_and_save(formatted_md):
        print("\né¢„å¤„ç†å®Œæˆï¼Markdown æ–‡ä»¶å·²æ›´æ–°è‡³ md/ ç›®å½•ã€‚")
        do_build = input("\næ˜¯å¦ç«‹å³ç”Ÿæˆ Word æ–‡æ¡£? (y/n) [y]: ").strip().lower()
        if do_build in ("", "y"):
            processor.run_build_engine()
    else:
        print("[Failed] æµç¨‹ä¸­æ­¢")


if __name__ == "__main__":
    main()
